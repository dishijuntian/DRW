{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee70beea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GPU-Enabled Cryptocurrency Market Prediction Pipeline\n",
    "====================================================\n",
    "A modular, object-oriented approach to cryptocurrency market prediction\n",
    "using ensemble methods with GPU acceleration.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import joblib\n",
    "import gc\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "from dataclasses import dataclass\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "# ML Libraries\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.base import clone\n",
    "from scipy.stats import pearsonr\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from koolbox import Trainer\n",
    "import optuna\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Configuration class for the prediction pipeline.\"\"\"\n",
    "    \n",
    "    # Data paths\n",
    "    train_path: str = \"kaggle/input/drw-crypto-market-prediction/train.parquet\"\n",
    "    test_path: str = \"kaggle/input/drw-crypto-market-prediction/test.parquet\"\n",
    "    sample_sub_path: str = \"kaggle/input/drw-crypto-market-prediction/sample_submission.csv\"\n",
    "    \n",
    "    # Model parameters\n",
    "    target: str = \"label\"\n",
    "    n_folds: int = 5\n",
    "    seed: int = 42\n",
    "    \n",
    "    # Optimization parameters\n",
    "    run_optuna: bool = True\n",
    "    n_optuna_trials: int = 250\n",
    "    \n",
    "    # GPU settings\n",
    "    use_gpu: bool = True\n",
    "    gpu_id: int = 0\n",
    "    \n",
    "    # Columns to drop\n",
    "    cols_to_drop: List[str] = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.cols_to_drop is None:\n",
    "            self.cols_to_drop = [\n",
    "                'X697', 'X698', 'X699', 'X700', 'X701', 'X702', 'X703', 'X704', 'X705', 'X706', \n",
    "                'X707', 'X708', 'X709', 'X710', 'X711', 'X712', 'X713', 'X714', 'X715', 'X716',\n",
    "                'X717', 'X864', 'X867', 'X869', 'X870', 'X871', 'X872', 'X104', 'X110', 'X116',\n",
    "                'X122', 'X128', 'X134', 'X140', 'X146', 'X152', 'X158', 'X164', 'X170', 'X176',\n",
    "                'X182', 'X351', 'X357', 'X363', 'X369', 'X375', 'X381', 'X387', 'X393', 'X399',\n",
    "                'X405', 'X411', 'X417', 'X423', 'X429'\n",
    "            ]\n",
    "\n",
    "\n",
    "class DataProcessor:\n",
    "    \"\"\"Handles data loading, preprocessing, and feature engineering.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        \n",
    "    def reduce_memory_usage(self, df: pd.DataFrame, dataset_name: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Optimize dataframe memory usage by downcasting numeric types.\n",
    "        \n",
    "        Args:\n",
    "            df: Input dataframe\n",
    "            dataset_name: Name for logging purposes\n",
    "            \n",
    "        Returns:\n",
    "            Memory-optimized dataframe\n",
    "        \"\"\"\n",
    "        print(f'Reducing memory usage for: {dataset_name}')\n",
    "        initial_mem = df.memory_usage().sum() / 1024**2\n",
    "        \n",
    "        for col in df.columns:\n",
    "            col_type = df[col].dtype\n",
    "            c_min, c_max = df[col].min(), df[col].max()\n",
    "            \n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        \n",
    "        final_mem = df.memory_usage().sum() / 1024**2\n",
    "        reduction = 100 * (initial_mem - final_mem) / initial_mem\n",
    "        \n",
    "        print(f'--- Memory usage before: {initial_mem:.2f} MB')\n",
    "        print(f'--- Memory usage after: {final_mem:.2f} MB')\n",
    "        print(f'--- Decreased memory usage by {reduction:.1f}%\\n')\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def create_interaction_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Create interaction features between different quantity types.\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Basic interactions\n",
    "        df['bid_ask_interaction'] = df['bid_qty'] * df['ask_qty']\n",
    "        df['bid_buy_interaction'] = df['bid_qty'] * df['buy_qty']\n",
    "        df['bid_sell_interaction'] = df['bid_qty'] * df['sell_qty']\n",
    "        df['ask_buy_interaction'] = df['ask_qty'] * df['buy_qty']\n",
    "        df['ask_sell_interaction'] = df['ask_qty'] * df['sell_qty']\n",
    "        df['buy_sell_interaction'] = df['buy_qty'] * df['sell_qty']\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def create_market_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Create advanced market microstructure features.\"\"\"\n",
    "        df = df.copy()\n",
    "        eps = 1e-8  # Small constant to avoid division by zero\n",
    "        \n",
    "        # Spread and ratio features\n",
    "        df['spread_indicator'] = (df['ask_qty'] - df['bid_qty']) / (df['ask_qty'] + df['bid_qty'] + eps)\n",
    "        df['buy_sell_ratio'] = df['buy_qty'] / (df['sell_qty'] + eps)\n",
    "        df['bid_ask_ratio'] = df['bid_qty'] / (df['ask_qty'] + eps)\n",
    "        \n",
    "        # Volume-weighted features\n",
    "        for qty_type in ['buy', 'sell', 'bid', 'ask']:\n",
    "            df[f'volume_weighted_{qty_type}'] = df[f'{qty_type}_qty'] * df['volume']\n",
    "        \n",
    "        # Order flow and pressure indicators\n",
    "        df['order_flow_imbalance'] = (df['buy_qty'] - df['sell_qty']) / (df['volume'] + eps)\n",
    "        df['buying_pressure'] = df['buy_qty'] / (df['volume'] + eps)\n",
    "        df['selling_pressure'] = df['sell_qty'] / (df['volume'] + eps)\n",
    "        \n",
    "        # Liquidity measures\n",
    "        df['total_liquidity'] = df['bid_qty'] + df['ask_qty']\n",
    "        df['liquidity_imbalance'] = (df['bid_qty'] - df['ask_qty']) / (df['total_liquidity'] + eps)\n",
    "        df['relative_spread'] = (df['ask_qty'] - df['bid_qty']) / (df['volume'] + eps)\n",
    "        \n",
    "        # Trade intensity and execution quality\n",
    "        df['trade_intensity'] = (df['buy_qty'] + df['sell_qty']) / (df['volume'] + eps)\n",
    "        df['avg_trade_size'] = df['volume'] / (df['buy_qty'] + df['sell_qty'] + eps)\n",
    "        df['net_trade_flow'] = (df['buy_qty'] - df['sell_qty']) / (df['buy_qty'] + df['sell_qty'] + eps)\n",
    "        \n",
    "        # Market depth and activity\n",
    "        df['depth_ratio'] = df['total_liquidity'] / (df['volume'] + eps)\n",
    "        df['volume_participation'] = (df['buy_qty'] + df['sell_qty']) / (df['total_liquidity'] + eps)\n",
    "        df['market_activity'] = df['volume'] * df['total_liquidity']\n",
    "        \n",
    "        # Advanced indicators\n",
    "        df['effective_spread_proxy'] = np.abs(df['buy_qty'] - df['sell_qty']) / (df['volume'] + eps)\n",
    "        df['realized_volatility_proxy'] = np.abs(df['order_flow_imbalance']) * df['volume']\n",
    "        df['normalized_buy_volume'] = df['buy_qty'] / (df['bid_qty'] + eps)\n",
    "        df['normalized_sell_volume'] = df['sell_qty'] / (df['ask_qty'] + eps)\n",
    "        \n",
    "        # Complex interactions\n",
    "        df['liquidity_adjusted_imbalance'] = df['order_flow_imbalance'] * df['depth_ratio']\n",
    "        df['pressure_spread_interaction'] = df['buying_pressure'] * df['spread_indicator']\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def clean_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Clean data by handling infinite values and NaNs.\"\"\"\n",
    "        df = df.replace([np.inf, -np.inf], np.nan)\n",
    "        df = df.fillna(0)\n",
    "        return df\n",
    "    \n",
    "    def load_and_process_data(self) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Load and process training and test data.\n",
    "        \n",
    "        Returns:\n",
    "            Tuple of (X_train, y_train, X_test)\n",
    "        \"\"\"\n",
    "        print(\"Loading data...\")\n",
    "        train = pd.read_parquet(self.config.train_path).reset_index(drop=True)\n",
    "        test = pd.read_parquet(self.config.test_path).reset_index(drop=True)\n",
    "        \n",
    "        # Drop unnecessary columns\n",
    "        train = train.drop(columns=self.config.cols_to_drop)\n",
    "        test = test.drop(columns=[\"label\"] + self.config.cols_to_drop)\n",
    "        \n",
    "        # Reduce memory usage\n",
    "        train = self.reduce_memory_usage(train, \"train\")\n",
    "        test = self.reduce_memory_usage(test, \"test\")\n",
    "        \n",
    "        print(\"Creating features...\")\n",
    "        # Feature engineering\n",
    "        train = self.create_interaction_features(train)\n",
    "        train = self.create_market_features(train)\n",
    "        train = self.clean_data(train)\n",
    "        \n",
    "        test = self.create_interaction_features(test)\n",
    "        test = self.create_market_features(test)\n",
    "        test = self.clean_data(test)\n",
    "        \n",
    "        # Split features and target\n",
    "        X_train = train.drop(self.config.target, axis=1)\n",
    "        y_train = train[self.config.target]\n",
    "        X_test = test\n",
    "        \n",
    "        print(f\"Training data shape: {X_train.shape}\")\n",
    "        print(f\"Test data shape: {X_test.shape}\")\n",
    "        print(f\"Number of features: {X_train.shape[1]}\")\n",
    "        \n",
    "        return X_train, y_train, X_test\n",
    "\n",
    "\n",
    "class BaseModel(ABC):\n",
    "    \"\"\"Abstract base class for all models.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.trainer = None\n",
    "        self.fold_scores = None\n",
    "        self.oof_preds = None\n",
    "        \n",
    "    @abstractmethod\n",
    "    def get_model_params(self) -> Dict[str, Any]:\n",
    "        \"\"\"Return model parameters.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_model_name(self) -> str:\n",
    "        \"\"\"Return model name.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def _pearsonr(self, y_true, y_pred):\n",
    "        \"\"\"Pearson correlation coefficient.\"\"\"\n",
    "        return pearsonr(y_true, y_pred)[0]\n",
    "    \n",
    "    def train(self, X: pd.DataFrame, y: pd.Series) -> Tuple[List[float], np.ndarray]:\n",
    "        \"\"\"\n",
    "        Train the model using cross-validation.\n",
    "        \n",
    "        Args:\n",
    "            X: Training features\n",
    "            y: Training target\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (fold_scores, oof_predictions)\n",
    "        \"\"\"\n",
    "        print(f\"Training {self.get_model_name()}...\")\n",
    "        \n",
    "        model_params = self.get_model_params()\n",
    "        model_class = self._get_model_class()\n",
    "        \n",
    "        self.trainer = Trainer(\n",
    "            model_class(**model_params),\n",
    "            cv=KFold(n_splits=self.config.n_folds, shuffle=False),\n",
    "            metric=self._pearsonr,\n",
    "            task=\"regression\",\n",
    "            metric_precision=6\n",
    "        )\n",
    "        \n",
    "        self.trainer.fit(X, y)\n",
    "        self.fold_scores = self.trainer.fold_scores\n",
    "        self.oof_preds = self.trainer.oof_preds\n",
    "        \n",
    "        print(f\"   Fold scores: {self.fold_scores}\")\n",
    "        print(f\"   Mean CV score: {np.mean(self.fold_scores):.6f}\")\n",
    "        print(f\"   Std CV score: {np.std(self.fold_scores):.6f}\")\n",
    "        \n",
    "        return self.fold_scores, self.oof_preds\n",
    "    \n",
    "    def predict(self, X: pd.DataFrame) -> np.ndarray:\n",
    "        \"\"\"Make predictions on new data.\"\"\"\n",
    "        if self.trainer is None:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        return self.trainer.predict(X)\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _get_model_class(self):\n",
    "        \"\"\"Return the model class.\"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class LightGBMModel(BaseModel):\n",
    "    \"\"\"LightGBM model with GPU support.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config, boosting_type: str = \"gbdt\"):\n",
    "        super().__init__(config)\n",
    "        self.boosting_type = boosting_type\n",
    "        \n",
    "    def get_model_name(self) -> str:\n",
    "        return f\"LightGBM ({self.boosting_type})\"\n",
    "    \n",
    "    def _get_model_class(self):\n",
    "        return LGBMRegressor\n",
    "    \n",
    "    def get_model_params(self) -> Dict[str, Any]:\n",
    "        \"\"\"Return optimized LightGBM parameters with GPU support.\"\"\"\n",
    "        base_params = {\n",
    "            \"random_state\": self.config.seed,\n",
    "            \"n_jobs\": -1,\n",
    "            \"verbose\": -1,\n",
    "            \"boosting_type\": self.boosting_type,\n",
    "        }\n",
    "        \n",
    "        # Add GPU support if enabled\n",
    "        if self.config.use_gpu:\n",
    "            base_params[\"device\"] = \"gpu\"\n",
    "            base_params[\"gpu_platform_id\"] = 0\n",
    "            base_params[\"gpu_device_id\"] = self.config.gpu_id\n",
    "        \n",
    "        if self.boosting_type == \"gbdt\":\n",
    "            specific_params = {\n",
    "                \"colsample_bytree\": 0.5625888953382505,\n",
    "                \"learning_rate\": 0.029312951475451557,\n",
    "                \"min_child_samples\": 63,\n",
    "                \"min_child_weight\": 0.11456572852335424,\n",
    "                \"n_estimators\": 126,\n",
    "                \"num_leaves\": 37,\n",
    "                \"reg_alpha\": 85.2476527854083,\n",
    "                \"reg_lambda\": 99.38305361388907,\n",
    "                \"subsample\": 0.450669817684892,\n",
    "            }\n",
    "        else:  # goss\n",
    "            specific_params = {\n",
    "                \"colsample_bytree\": 0.34695458228489784,\n",
    "                \"learning_rate\": 0.031023014900595287,\n",
    "                \"min_child_samples\": 30,\n",
    "                \"min_child_weight\": 0.4727729225033618,\n",
    "                \"n_estimators\": 220,\n",
    "                \"num_leaves\": 58,\n",
    "                \"reg_alpha\": 38.665994901468224,\n",
    "                \"reg_lambda\": 92.76991677464294,\n",
    "                \"subsample\": 0.4810891284493255,\n",
    "            }\n",
    "        \n",
    "        return {**base_params, **specific_params}\n",
    "\n",
    "\n",
    "class XGBoostModel(BaseModel):\n",
    "    \"\"\"XGBoost model with GPU support.\"\"\"\n",
    "    \n",
    "    def get_model_name(self) -> str:\n",
    "        return \"XGBoost\"\n",
    "    \n",
    "    def _get_model_class(self):\n",
    "        return XGBRegressor\n",
    "    \n",
    "    def get_model_params(self) -> Dict[str, Any]:\n",
    "        \"\"\"Return optimized XGBoost parameters with GPU support.\"\"\"\n",
    "        params = {\n",
    "            \"random_state\": self.config.seed,\n",
    "            \"n_jobs\": -1,\n",
    "            \"verbosity\": 0,\n",
    "            \"colsample_bylevel\": 0.4778015829774066,\n",
    "            \"colsample_bynode\": 0.362764358742407,\n",
    "            \"colsample_bytree\": 0.7107423488010493,\n",
    "            \"gamma\": 1.7094857725240398,\n",
    "            \"learning_rate\": 0.02213323588455387,\n",
    "            \"max_depth\": 20,\n",
    "            \"max_leaves\": 12,\n",
    "            \"min_child_weight\": 16,\n",
    "            \"n_estimators\": 1667,\n",
    "            \"reg_alpha\": 39.352415706891264,\n",
    "            \"reg_lambda\": 75.44843704068275,\n",
    "            \"subsample\": 0.06566669853471274,\n",
    "        }\n",
    "        \n",
    "        # Add GPU support if enabled\n",
    "        if self.config.use_gpu:\n",
    "            params[\"tree_method\"] = \"gpu_hist\"\n",
    "            params[\"gpu_id\"] = self.config.gpu_id\n",
    "        \n",
    "        return params\n",
    "\n",
    "\n",
    "class EnsembleModel:\n",
    "    \"\"\"Ridge regression ensemble model.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.best_params = None\n",
    "        self.trainer = None\n",
    "        self.coefficients = None\n",
    "        \n",
    "    def _pearsonr(self, y_true, y_pred):\n",
    "        \"\"\"Pearson correlation coefficient.\"\"\"\n",
    "        return pearsonr(y_true, y_pred)[0]\n",
    "    \n",
    "    def _optimize_hyperparameters(self, X: pd.DataFrame, y: pd.Series) -> Dict[str, Any]:\n",
    "        \"\"\"Optimize Ridge hyperparameters using Optuna.\"\"\"\n",
    "        \n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                \"random_state\": self.config.seed,\n",
    "                \"alpha\": trial.suggest_float(\"alpha\", 0, 1000),\n",
    "                \"tol\": trial.suggest_float(\"tol\", 1e-6, 1e-2),\n",
    "                \"fit_intercept\": trial.suggest_categorical(\"fit_intercept\", [True, False]),\n",
    "                \"positive\": trial.suggest_categorical(\"positive\", [True, False])\n",
    "            }\n",
    "            \n",
    "            trainer = Trainer(\n",
    "                Ridge(**params),\n",
    "                cv=KFold(n_splits=self.config.n_folds, shuffle=False),\n",
    "                metric=self._pearsonr,\n",
    "                task=\"regression\",\n",
    "                verbose=False\n",
    "            )\n",
    "            trainer.fit(X, y)\n",
    "            \n",
    "            return np.mean(trainer.fold_scores)\n",
    "        \n",
    "        print(\"Optimizing Ridge hyperparameters with Optuna...\")\n",
    "        sampler = optuna.samplers.TPESampler(seed=self.config.seed, multivariate=True)\n",
    "        study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "        study.optimize(objective, n_trials=self.config.n_optuna_trials, n_jobs=-1, catch=(ValueError,))\n",
    "        \n",
    "        best_params = study.best_params\n",
    "        print(f\"Best parameters found: {best_params}\")\n",
    "        print(f\"Best CV score: {study.best_value:.6f}\")\n",
    "        \n",
    "        # Cleanup\n",
    "        del study\n",
    "        gc.collect()\n",
    "        \n",
    "        return best_params\n",
    "    \n",
    "    def train(self, oof_predictions: Dict[str, np.ndarray], y: pd.Series) -> Tuple[List[float], np.ndarray]:\n",
    "        \"\"\"\n",
    "        Train the ensemble model.\n",
    "        \n",
    "        Args:\n",
    "            oof_predictions: Dictionary of out-of-fold predictions from base models\n",
    "            y: Target values\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (fold_scores, coefficients)\n",
    "        \"\"\"\n",
    "        X_oof = pd.DataFrame(oof_predictions)\n",
    "        \n",
    "        # Optimize hyperparameters if enabled\n",
    "        if self.config.run_optuna:\n",
    "            self.best_params = self._optimize_hyperparameters(X_oof, y)\n",
    "            ridge_params = {\n",
    "                \"random_state\": self.config.seed,\n",
    "                **self.best_params\n",
    "            }\n",
    "        else:\n",
    "            ridge_params = {\"random_state\": self.config.seed}\n",
    "        \n",
    "        print(\"Training final Ridge ensemble...\")\n",
    "        self.trainer = Trainer(\n",
    "            Ridge(**ridge_params),\n",
    "            cv=KFold(n_splits=self.config.n_folds, shuffle=False),\n",
    "            metric=self._pearsonr,\n",
    "            task=\"regression\",\n",
    "            metric_precision=6\n",
    "        )\n",
    "        \n",
    "        self.trainer.fit(X_oof, y)\n",
    "        \n",
    "        # Calculate average coefficients\n",
    "        self.coefficients = np.zeros((1, X_oof.shape[1]))\n",
    "        for estimator in self.trainer.estimators:\n",
    "            self.coefficients += estimator.coef_\n",
    "        self.coefficients = self.coefficients / len(self.trainer.estimators)\n",
    "        \n",
    "        fold_scores = self.trainer.fold_scores\n",
    "        print(f\"   Fold scores: {fold_scores}\")\n",
    "        print(f\"   Mean CV score: {np.mean(fold_scores):.6f}\")\n",
    "        print(f\"   Std CV score: {np.std(fold_scores):.6f}\")\n",
    "        \n",
    "        return fold_scores, self.coefficients\n",
    "    \n",
    "    def predict(self, test_predictions: Dict[str, np.ndarray]) -> np.ndarray:\n",
    "        \"\"\"Make ensemble predictions.\"\"\"\n",
    "        X_test = pd.DataFrame(test_predictions)\n",
    "        return self.trainer.predict(X_test)\n",
    "\n",
    "\n",
    "class Visualizer:\n",
    "    \"\"\"Handles all visualization tasks.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_ensemble_weights(coefficients: np.ndarray, model_names: List[str], title: str = \"Ridge Ensemble Coefficients\"):\n",
    "        \"\"\"Plot ensemble model coefficients.\"\"\"\n",
    "        sorted_indices = np.argsort(coefficients[0])[::-1]\n",
    "        sorted_coeffs = coefficients[0][sorted_indices]\n",
    "        sorted_names = np.array(model_names)[sorted_indices]\n",
    "        \n",
    "        plt.figure(figsize=(10, len(model_names) * 0.5))\n",
    "        ax = sns.barplot(x=sorted_coeffs, y=sorted_names, palette=\"RdYlGn_r\")\n",
    "        \n",
    "        for i, (value, name) in enumerate(zip(sorted_coeffs, sorted_names)):\n",
    "            ha = \"left\" if value >= 0 else \"right\"\n",
    "            ax.text(value, i, f\"{value:.3f}\", va=\"center\", ha=ha, color=\"black\")\n",
    "        \n",
    "        xlim = ax.get_xlim()\n",
    "        ax.set_xlim(xlim[0] - 0.1 * abs(xlim[0]), xlim[1] + 0.1 * abs(xlim[1]))\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"\")\n",
    "        plt.ylabel(\"\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_model_performance(scores: Dict[str, List[float]]):\n",
    "        \"\"\"Plot model performance comparison.\"\"\"\n",
    "        scores_df = pd.DataFrame(scores)\n",
    "        mean_scores = scores_df.mean().sort_values(ascending=False)\n",
    "        \n",
    "        # Calculate plot limits\n",
    "        min_score, max_score = mean_scores.min(), mean_scores.max()\n",
    "        padding = (max_score - min_score) * 0.5\n",
    "        lower_limit = min_score - padding\n",
    "        upper_limit = max_score + padding\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, len(scores) * 0.5))\n",
    "        \n",
    "        # Box plot\n",
    "        sns.boxplot(data=scores_df, order=mean_scores.index, ax=ax1, orient=\"h\", color=\"grey\")\n",
    "        ax1.set_title(\"Fold Score Distribution\")\n",
    "        ax1.set_xlabel(\"\")\n",
    "        ax1.set_ylabel(\"\")\n",
    "        \n",
    "        # Bar plot\n",
    "        barplot = sns.barplot(x=mean_scores.values, y=mean_scores.index, ax=ax2, color=\"grey\")\n",
    "        ax2.set_title(\"Average Score\")\n",
    "        ax2.set_xlabel(\"\")\n",
    "        ax2.set_xlim(left=lower_limit, right=upper_limit)\n",
    "        ax2.set_ylabel(\"\")\n",
    "        \n",
    "        # Highlight ensemble model\n",
    "        for i, (score, model) in enumerate(zip(mean_scores.values, mean_scores.index)):\n",
    "            color = \"cyan\" if \"ensemble\" in model.lower() else \"grey\"\n",
    "            barplot.patches[i].set_facecolor(color)\n",
    "            ax1.patches[i].set_facecolor(color)\n",
    "            barplot.text(score, i, f\"{score:.6f}\", va=\"center\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "class CryptoPredictor:\n",
    "    \"\"\"Main prediction pipeline class.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.data_processor = DataProcessor(config)\n",
    "        self.visualizer = Visualizer()\n",
    "        \n",
    "        # Initialize models\n",
    "        self.models = [\n",
    "            LightGBMModel(config, boosting_type=\"gbdt\"),\n",
    "            LightGBMModel(config, boosting_type=\"goss\"),\n",
    "            XGBoostModel(config)\n",
    "        ]\n",
    "        \n",
    "        self.ensemble = EnsembleModel(config)\n",
    "        self.results = {}\n",
    "        \n",
    "    def run_pipeline(self) -> str:\n",
    "        \"\"\"\n",
    "        Run the complete prediction pipeline.\n",
    "        \n",
    "        Returns:\n",
    "            Filename of the saved submission\n",
    "        \"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"CRYPTO MARKET PREDICTION PIPELINE\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Load and process data\n",
    "        X_train, y_train, X_test = self.data_processor.load_and_process_data()\n",
    "        \n",
    "        # Train base models\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"TRAINING BASE MODELS\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        oof_predictions = {}\n",
    "        test_predictions = {}\n",
    "        all_scores = {}\n",
    "        \n",
    "        for model in self.models:\n",
    "            fold_scores, oof_preds = model.train(X_train, y_train)\n",
    "            test_preds = model.predict(X_test)\n",
    "            \n",
    "            model_name = model.get_model_name()\n",
    "            all_scores[model_name] = fold_scores\n",
    "            oof_predictions[model_name] = oof_preds\n",
    "            test_predictions[model_name] = test_preds\n",
    "            \n",
    "            # Cleanup\n",
    "            del model.trainer\n",
    "            gc.collect()\n",
    "        \n",
    "        # Save base model predictions\n",
    "        joblib.dump(pd.DataFrame(oof_predictions), \"oof_preds.pkl\")\n",
    "        joblib.dump(pd.DataFrame(test_predictions), \"test_preds.pkl\")\n",
    "        \n",
    "        # Train ensemble model\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"TRAINING ENSEMBLE MODEL\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        ensemble_scores, coefficients = self.ensemble.train(oof_predictions, y_train)\n",
    "        ensemble_test_preds = self.ensemble.predict(test_predictions)\n",
    "        \n",
    "        all_scores[\"Ridge (ensemble)\"] = ensemble_scores\n",
    "        \n",
    "        # Print results summary\n",
    "        self._print_results_summary(all_scores)\n",
    "        \n",
    "        # Visualizations\n",
    "        print(\"\\nGenerating visualizations...\")\n",
    "        self.visualizer.plot_ensemble_weights(\n",
    "            coefficients, \n",
    "            list(oof_predictions.keys()),\n",
    "            \"Ridge Ensemble Coefficients\"\n",
    "        )\n",
    "        self.visualizer.plot_model_performance(all_scores)\n",
    "        \n",
    "        # Save submission\n",
    "        submission_filename = self._save_submission(ensemble_test_preds, ensemble_scores)\n",
    "        \n",
    "        print(f\"\\n\" + \"=\" * 60)\n",
    "        print(f\"Submission saved as: {submission_filename}\")\n",
    "        print(f\"Final ensemble CV score: {np.mean(ensemble_scores):.6f}\")\n",
    "        print(\"=\" * 60)\n",
    "        print(\"Process completed successfully!\")\n",
    "        \n",
    "        return submission_filename\n",
    "    \n",
    "    def _print_results_summary(self, scores: Dict[str, List[float]]):\n",
    "        \"\"\"Print detailed results summary.\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"FINAL MODEL PERFORMANCE SUMMARY\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        scores_df = pd.DataFrame(scores)\n",
    "        mean_scores = scores_df.mean().sort_values(ascending=False)\n",
    "        \n",
    "        print(\"\\nModel Rankings (by mean CV score):\")\n",
    "        print(\"-\" * 40)\n",
    "        for i, (model, score) in enumerate(mean_scores.items(), 1):\n",
    "            std_score = scores_df[model].std()\n",
    "            print(f\"{i}. {model:20s} - Mean: {score:.6f} (±{std_score:.6f})\")\n",
    "        \n",
    "        print(\"\\nDetailed Fold Scores:\")\n",
    "        print(\"-\" * 40)\n",
    "        for model in mean_scores.index:\n",
    "            fold_scores = scores[model]\n",
    "            print(f\"\\n{model}:\")\n",
    "            for fold, score in enumerate(fold_scores, 1):\n",
    "                print(f\"   Fold {fold}: {score:.6f}\")\n",
    "    \n",
    "    def _save_submission(self, predictions: np.ndarray, scores: List[float]) -> str:\n",
    "        \"\"\"Save predictions to submission file.\"\"\"\n",
    "        sub = pd.read_csv(self.config.sample_sub_path)\n",
    "        sub[\"prediction\"] = predictions\n",
    "        \n",
    "        mean_score = np.mean(scores)\n",
    "        filename = f\"sub_ridge_{mean_score:.6f}.csv\"\n",
    "        sub.to_csv(filename, index=False)\n",
    "        \n",
    "        return filename\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74d54e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CRYPTO MARKET PREDICTION PIPELINE\n",
      "============================================================\n",
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    # Initialize configuration\n",
    "    config = Config(\n",
    "        use_gpu=True,  # Set to False if GPU is not available\n",
    "        run_optuna=True,\n",
    "        n_optuna_trials=250\n",
    "    )\n",
    "    \n",
    "    # Create and run predictor\n",
    "    predictor = CryptoPredictor(config)\n",
    "    submission_file = predictor.run_pipeline()\n",
    "    \n",
    "    print(f\"\\nPrediction pipeline completed!\")\n",
    "    print(f\"Submission file: {submission_file}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad3dce5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
