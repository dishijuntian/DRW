{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "953c364a",
   "metadata": {},
   "source": [
    "## å¯¼å…¥ä¾èµ–åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee70beea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import joblib\n",
    "import gc\n",
    "import os\n",
    "import json\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "from dataclasses import dataclass\n",
    "from abc import ABC, abstractmethod\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.base import clone\n",
    "from scipy.stats import pearsonr\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from koolbox import Trainer\n",
    "import optuna\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0988fe3e",
   "metadata": {},
   "source": [
    "## è¿è¡Œé…ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9392a2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Configuration class for the prediction pipeline.\"\"\"\n",
    "    \n",
    "    # Updated data paths to match directory structure\n",
    "    train_path: str = \"../kaggle/input/drw-crypto-market-prediction/train.parquet\"\n",
    "    test_path: str = \"../kaggle/input/drw-crypto-market-prediction/test.parquet\"\n",
    "    sample_sub_path: str = \"../kaggle/input/drw-crypto-market-prediction/sample_submission.csv\"\n",
    "    \n",
    "    # Output paths\n",
    "    models_dir: str = \"../models/\"\n",
    "    results_dir: str = \"../result/\"\n",
    "    \n",
    "    # Model parameters\n",
    "    target: str = \"label\"\n",
    "    n_folds: int = 5\n",
    "    seed: int = 42\n",
    "    \n",
    "    # Optimization parameters\n",
    "    run_optuna: bool = True\n",
    "    n_optuna_trials: int = 100  # Reduced for notebook execution\n",
    "    \n",
    "    # GPU settings\n",
    "    use_gpu: bool = True  # Set to False if GPU is not available\n",
    "    gpu_id: int = 0\n",
    "    \n",
    "    # Columns to drop\n",
    "    cols_to_drop: List[str] = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        # Create directories if they don't exist\n",
    "        os.makedirs(self.models_dir, exist_ok=True)\n",
    "        os.makedirs(self.results_dir, exist_ok=True)\n",
    "        \n",
    "        if self.cols_to_drop is None:\n",
    "            self.cols_to_drop = [\n",
    "                'X697', 'X698', 'X699', 'X700', 'X701', 'X702', 'X703', 'X704', 'X705', 'X706', \n",
    "                'X707', 'X708', 'X709', 'X710', 'X711', 'X712', 'X713', 'X714', 'X715', 'X716',\n",
    "                'X717', 'X864', 'X867', 'X869', 'X870', 'X871', 'X872', 'X104', 'X110', 'X116',\n",
    "                'X122', 'X128', 'X134', 'X140', 'X146', 'X152', 'X158', 'X164', 'X170', 'X176',\n",
    "                'X182', 'X351', 'X357', 'X363', 'X369', 'X375', 'X381', 'X387', 'X393', 'X399',\n",
    "                'X405', 'X411', 'X417', 'X423', 'X429'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b680c5",
   "metadata": {},
   "source": [
    "## æ•°æ®é¢„å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dcfeb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    \"\"\"Handles data loading, preprocessing, and feature engineering.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        \n",
    "    def reduce_memory_usage(self, df: pd.DataFrame, dataset_name: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Optimize dataframe memory usage by downcasting numeric types.\n",
    "        \n",
    "        Args:\n",
    "            df: Input dataframe\n",
    "            dataset_name: Name for logging purposes\n",
    "            \n",
    "        Returns:\n",
    "            Memory-optimized dataframe\n",
    "        \"\"\"\n",
    "        print(f'Reducing memory usage for: {dataset_name}')\n",
    "        initial_mem = df.memory_usage().sum() / 1024**2\n",
    "        \n",
    "        for col in df.columns:\n",
    "            col_type = df[col].dtype\n",
    "            c_min, c_max = df[col].min(), df[col].max()\n",
    "            \n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        \n",
    "        final_mem = df.memory_usage().sum() / 1024**2\n",
    "        reduction = 100 * (initial_mem - final_mem) / initial_mem\n",
    "        \n",
    "        print(f'--- Memory usage before: {initial_mem:.2f} MB')\n",
    "        print(f'--- Memory usage after: {final_mem:.2f} MB')\n",
    "        print(f'--- Decreased memory usage by {reduction:.1f}%\\n')\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def create_interaction_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Create interaction features between different quantity types.\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Basic interactions\n",
    "        df['bid_ask_interaction'] = df['bid_qty'] * df['ask_qty']\n",
    "        df['bid_buy_interaction'] = df['bid_qty'] * df['buy_qty']\n",
    "        df['bid_sell_interaction'] = df['bid_qty'] * df['sell_qty']\n",
    "        df['ask_buy_interaction'] = df['ask_qty'] * df['buy_qty']\n",
    "        df['ask_sell_interaction'] = df['ask_qty'] * df['sell_qty']\n",
    "        df['buy_sell_interaction'] = df['buy_qty'] * df['sell_qty']\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def create_market_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Create advanced market microstructure features.\"\"\"\n",
    "        df = df.copy()\n",
    "        eps = 1e-8  # Small constant to avoid division by zero\n",
    "        \n",
    "        # Spread and ratio features\n",
    "        df['spread_indicator'] = (df['ask_qty'] - df['bid_qty']) / (df['ask_qty'] + df['bid_qty'] + eps)\n",
    "        df['buy_sell_ratio'] = df['buy_qty'] / (df['sell_qty'] + eps)\n",
    "        df['bid_ask_ratio'] = df['bid_qty'] / (df['ask_qty'] + eps)\n",
    "        \n",
    "        # Volume-weighted features\n",
    "        for qty_type in ['buy', 'sell', 'bid', 'ask']:\n",
    "            df[f'volume_weighted_{qty_type}'] = df[f'{qty_type}_qty'] * df['volume']\n",
    "        \n",
    "        # Order flow and pressure indicators\n",
    "        df['order_flow_imbalance'] = (df['buy_qty'] - df['sell_qty']) / (df['volume'] + eps)\n",
    "        df['buying_pressure'] = df['buy_qty'] / (df['volume'] + eps)\n",
    "        df['selling_pressure'] = df['sell_qty'] / (df['volume'] + eps)\n",
    "        \n",
    "        # Liquidity measures\n",
    "        df['total_liquidity'] = df['bid_qty'] + df['ask_qty']\n",
    "        df['liquidity_imbalance'] = (df['bid_qty'] - df['ask_qty']) / (df['total_liquidity'] + eps)\n",
    "        df['relative_spread'] = (df['ask_qty'] - df['bid_qty']) / (df['volume'] + eps)\n",
    "        \n",
    "        # Trade intensity and execution quality\n",
    "        df['trade_intensity'] = (df['buy_qty'] + df['sell_qty']) / (df['volume'] + eps)\n",
    "        df['avg_trade_size'] = df['volume'] / (df['buy_qty'] + df['sell_qty'] + eps)\n",
    "        df['net_trade_flow'] = (df['buy_qty'] - df['sell_qty']) / (df['buy_qty'] + df['sell_qty'] + eps)\n",
    "        \n",
    "        # Market depth and activity\n",
    "        df['depth_ratio'] = df['total_liquidity'] / (df['volume'] + eps)\n",
    "        df['volume_participation'] = (df['buy_qty'] + df['sell_qty']) / (df['total_liquidity'] + eps)\n",
    "        df['market_activity'] = df['volume'] * df['total_liquidity']\n",
    "        \n",
    "        # Advanced indicators\n",
    "        df['effective_spread_proxy'] = np.abs(df['buy_qty'] - df['sell_qty']) / (df['volume'] + eps)\n",
    "        df['realized_volatility_proxy'] = np.abs(df['order_flow_imbalance']) * df['volume']\n",
    "        df['normalized_buy_volume'] = df['buy_qty'] / (df['bid_qty'] + eps)\n",
    "        df['normalized_sell_volume'] = df['sell_qty'] / (df['ask_qty'] + eps)\n",
    "        \n",
    "        # Complex interactions\n",
    "        df['liquidity_adjusted_imbalance'] = df['order_flow_imbalance'] * df['depth_ratio']\n",
    "        df['pressure_spread_interaction'] = df['buying_pressure'] * df['spread_indicator']\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def clean_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Clean data by handling infinite values and NaNs.\"\"\"\n",
    "        df = df.replace([np.inf, -np.inf], np.nan)\n",
    "        df = df.fillna(0)\n",
    "        return df\n",
    "    \n",
    "    def load_and_process_data(self) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Load and process training and test data.\n",
    "        \n",
    "        Returns:\n",
    "            Tuple of (X_train, y_train, X_test)\n",
    "        \"\"\"\n",
    "        print(\"Loading data...\")\n",
    "        train = pd.read_parquet(self.config.train_path).reset_index(drop=True)\n",
    "        test = pd.read_parquet(self.config.test_path).reset_index(drop=True)\n",
    "        \n",
    "        # Drop unnecessary columns\n",
    "        train = train.drop(columns=self.config.cols_to_drop)\n",
    "        test = test.drop(columns=[\"label\"] + self.config.cols_to_drop)\n",
    "        \n",
    "        # Reduce memory usage\n",
    "        train = self.reduce_memory_usage(train, \"train\")\n",
    "        test = self.reduce_memory_usage(test, \"test\")\n",
    "        \n",
    "        print(\"Creating features...\")\n",
    "        # Feature engineering\n",
    "        train = self.create_interaction_features(train)\n",
    "        train = self.create_market_features(train)\n",
    "        train = self.clean_data(train)\n",
    "        \n",
    "        test = self.create_interaction_features(test)\n",
    "        test = self.create_market_features(test)\n",
    "        test = self.clean_data(test)\n",
    "        \n",
    "        # Split features and target\n",
    "        X_train = train.drop(self.config.target, axis=1)\n",
    "        y_train = train[self.config.target]\n",
    "        X_test = test\n",
    "        \n",
    "        print(f\"Training data shape: {X_train.shape}\")\n",
    "        print(f\"Test data shape: {X_test.shape}\")\n",
    "        print(f\"Number of features: {X_train.shape[1]}\")\n",
    "        \n",
    "        return X_train, y_train, X_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27450ec2",
   "metadata": {},
   "source": [
    "# åŸºç¡€æ¨¡åž‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74d54e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(ABC):\n",
    "    \"\"\"Abstract base class for all models.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.trainer = None\n",
    "        self.fold_scores = None\n",
    "        self.oof_preds = None\n",
    "        \n",
    "    @abstractmethod\n",
    "    def get_model_params(self) -> Dict[str, Any]:\n",
    "        \"\"\"Return model parameters.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_model_name(self) -> str:\n",
    "        \"\"\"Return model name.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def _pearsonr(self, y_true, y_pred):\n",
    "        \"\"\"Pearson correlation coefficient.\"\"\"\n",
    "        return pearsonr(y_true, y_pred)[0]\n",
    "    \n",
    "    def train(self, X: pd.DataFrame, y: pd.Series) -> Tuple[List[float], np.ndarray]:\n",
    "        \"\"\"\n",
    "        Train the model using cross-validation.\n",
    "        \n",
    "        Args:\n",
    "            X: Training features\n",
    "            y: Training target\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (fold_scores, oof_predictions)\n",
    "        \"\"\"\n",
    "        print(f\"Training {self.get_model_name()}...\")\n",
    "        \n",
    "        model_params = self.get_model_params()\n",
    "        model_class = self._get_model_class()\n",
    "        \n",
    "        self.trainer = Trainer(\n",
    "            model_class(**model_params),\n",
    "            cv=KFold(n_splits=self.config.n_folds, shuffle=False),\n",
    "            metric=self._pearsonr,\n",
    "            task=\"regression\",\n",
    "            metric_precision=6\n",
    "        )\n",
    "        \n",
    "        self.trainer.fit(X, y)\n",
    "        self.fold_scores = self.trainer.fold_scores\n",
    "        self.oof_preds = self.trainer.oof_preds\n",
    "        \n",
    "        print(f\"   Fold scores: {self.fold_scores}\")\n",
    "        print(f\"   Mean CV score: {np.mean(self.fold_scores):.6f}\")\n",
    "        print(f\"   Std CV score: {np.std(self.fold_scores):.6f}\")\n",
    "        \n",
    "        return self.fold_scores, self.oof_preds\n",
    "    \n",
    "    def predict(self, X: pd.DataFrame) -> np.ndarray:\n",
    "        \"\"\"Make predictions on new data.\"\"\"\n",
    "        if self.trainer is None:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        return self.trainer.predict(X)\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _get_model_class(self):\n",
    "        \"\"\"Return the model class.\"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class LightGBMModel(BaseModel):\n",
    "    \"\"\"LightGBM model with GPU support.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config, boosting_type: str = \"gbdt\"):\n",
    "        super().__init__(config)\n",
    "        self.boosting_type = boosting_type\n",
    "        \n",
    "    def get_model_name(self) -> str:\n",
    "        return f\"LightGBM ({self.boosting_type})\"\n",
    "    \n",
    "    def _get_model_class(self):\n",
    "        return LGBMRegressor\n",
    "    \n",
    "    def get_model_params(self) -> Dict[str, Any]:\n",
    "        \"\"\"Return optimized LightGBM parameters with GPU support.\"\"\"\n",
    "        base_params = {\n",
    "            \"random_state\": self.config.seed,\n",
    "            \"n_jobs\": -1,\n",
    "            \"verbose\": -1,\n",
    "            \"boosting_type\": self.boosting_type,\n",
    "        }\n",
    "        \n",
    "        # Add GPU support if enabled\n",
    "        if self.config.use_gpu:\n",
    "            base_params[\"device\"] = \"gpu\"\n",
    "            base_params[\"gpu_platform_id\"] = 0\n",
    "            base_params[\"gpu_device_id\"] = self.config.gpu_id\n",
    "        \n",
    "        if self.boosting_type == \"gbdt\":\n",
    "            specific_params = {\n",
    "                \"colsample_bytree\": 0.5625888953382505,\n",
    "                \"learning_rate\": 0.029312951475451557,\n",
    "                \"min_child_samples\": 63,\n",
    "                \"min_child_weight\": 0.11456572852335424,\n",
    "                \"n_estimators\": 126,\n",
    "                \"num_leaves\": 37,\n",
    "                \"reg_alpha\": 85.2476527854083,\n",
    "                \"reg_lambda\": 99.38305361388907,\n",
    "                \"subsample\": 0.450669817684892,\n",
    "            }\n",
    "        else:  # goss\n",
    "            specific_params = {\n",
    "                \"colsample_bytree\": 0.34695458228489784,\n",
    "                \"learning_rate\": 0.031023014900595287,\n",
    "                \"min_child_samples\": 30,\n",
    "                \"min_child_weight\": 0.4727729225033618,\n",
    "                \"n_estimators\": 220,\n",
    "                \"num_leaves\": 58,\n",
    "                \"reg_alpha\": 38.665994901468224,\n",
    "                \"reg_lambda\": 92.76991677464294,\n",
    "                \"subsample\": 0.4810891284493255,\n",
    "            }\n",
    "        \n",
    "        return {**base_params, **specific_params}\n",
    "\n",
    "\n",
    "class XGBoostModel(BaseModel):\n",
    "    \"\"\"XGBoost model with GPU support.\"\"\"\n",
    "    \n",
    "    def get_model_name(self) -> str:\n",
    "        return \"XGBoost\"\n",
    "    \n",
    "    def _get_model_class(self):\n",
    "        return XGBRegressor\n",
    "    \n",
    "    def get_model_params(self) -> Dict[str, Any]:\n",
    "        \"\"\"Return optimized XGBoost parameters with GPU support.\"\"\"\n",
    "        params = {\n",
    "            \"random_state\": self.config.seed,\n",
    "            \"n_jobs\": -1,\n",
    "            \"verbosity\": 0,\n",
    "            \"colsample_bylevel\": 0.4778015829774066,\n",
    "            \"colsample_bynode\": 0.362764358742407,\n",
    "            \"colsample_bytree\": 0.7107423488010493,\n",
    "            \"gamma\": 1.7094857725240398,\n",
    "            \"learning_rate\": 0.02213323588455387,\n",
    "            \"max_depth\": 20,\n",
    "            \"max_leaves\": 12,\n",
    "            \"min_child_weight\": 16,\n",
    "            \"n_estimators\": 1667,\n",
    "            \"reg_alpha\": 39.352415706891264,\n",
    "            \"reg_lambda\": 75.44843704068275,\n",
    "            \"subsample\": 0.06566669853471274,\n",
    "        }\n",
    "        \n",
    "        # Add GPU support if enabled\n",
    "        if self.config.use_gpu:\n",
    "            params[\"tree_method\"] = \"gpu_hist\"\n",
    "            params[\"gpu_id\"] = self.config.gpu_id\n",
    "        \n",
    "        return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59081d66",
   "metadata": {},
   "source": [
    "## æ•´åˆæ¨¡åž‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ad3dce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleModel:\n",
    "    \"\"\"Ridge regression ensemble model.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.best_params = None\n",
    "        self.trainer = None\n",
    "        self.coefficients = None\n",
    "        \n",
    "    def _pearsonr(self, y_true, y_pred):\n",
    "        \"\"\"Pearson correlation coefficient.\"\"\"\n",
    "        return pearsonr(y_true, y_pred)[0]\n",
    "    \n",
    "    def _optimize_hyperparameters(self, X: pd.DataFrame, y: pd.Series) -> Dict[str, Any]:\n",
    "        \"\"\"Optimize Ridge hyperparameters using Optuna.\"\"\"\n",
    "        \n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                \"random_state\": self.config.seed,\n",
    "                \"alpha\": trial.suggest_float(\"alpha\", 0, 1000),\n",
    "                \"tol\": trial.suggest_float(\"tol\", 1e-6, 1e-2),\n",
    "                \"fit_intercept\": trial.suggest_categorical(\"fit_intercept\", [True, False]),\n",
    "                \"positive\": trial.suggest_categorical(\"positive\", [True, False])\n",
    "            }\n",
    "            \n",
    "            trainer = Trainer(\n",
    "                Ridge(**params),\n",
    "                cv=KFold(n_splits=self.config.n_folds, shuffle=False),\n",
    "                metric=self._pearsonr,\n",
    "                task=\"regression\",\n",
    "                verbose=False\n",
    "            )\n",
    "            trainer.fit(X, y)\n",
    "            \n",
    "            return np.mean(trainer.fold_scores)\n",
    "        \n",
    "        print(\"Optimizing Ridge hyperparameters with Optuna...\")\n",
    "        sampler = optuna.samplers.TPESampler(seed=self.config.seed, multivariate=True)\n",
    "        study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "        study.optimize(objective, n_trials=self.config.n_optuna_trials, n_jobs=-1, catch=(ValueError,))\n",
    "        \n",
    "        best_params = study.best_params\n",
    "        print(f\"Best parameters found: {best_params}\")\n",
    "        print(f\"Best CV score: {study.best_value:.6f}\")\n",
    "        \n",
    "        # Cleanup\n",
    "        del study\n",
    "        gc.collect()\n",
    "        \n",
    "        return best_params\n",
    "    \n",
    "    def train(self, oof_predictions: Dict[str, np.ndarray], y: pd.Series) -> Tuple[List[float], np.ndarray]:\n",
    "        \"\"\"\n",
    "        Train the ensemble model.\n",
    "        \n",
    "        Args:\n",
    "            oof_predictions: Dictionary of out-of-fold predictions from base models\n",
    "            y: Target values\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (fold_scores, coefficients)\n",
    "        \"\"\"\n",
    "        X_oof = pd.DataFrame(oof_predictions)\n",
    "        \n",
    "        # Optimize hyperparameters if enabled\n",
    "        if self.config.run_optuna:\n",
    "            self.best_params = self._optimize_hyperparameters(X_oof, y)\n",
    "            ridge_params = {\n",
    "                \"random_state\": self.config.seed,\n",
    "                **self.best_params\n",
    "            }\n",
    "        else:\n",
    "            ridge_params = {\"random_state\": self.config.seed}\n",
    "        \n",
    "        print(\"Training final Ridge ensemble...\")\n",
    "        self.trainer = Trainer(\n",
    "            Ridge(**ridge_params),\n",
    "            cv=KFold(n_splits=self.config.n_folds, shuffle=False),\n",
    "            metric=self._pearsonr,\n",
    "            task=\"regression\",\n",
    "            metric_precision=6\n",
    "        )\n",
    "        \n",
    "        self.trainer.fit(X_oof, y)\n",
    "        \n",
    "        # Calculate average coefficients\n",
    "        self.coefficients = np.zeros((1, X_oof.shape[1]))\n",
    "        for estimator in self.trainer.estimators:\n",
    "            self.coefficients += estimator.coef_\n",
    "        self.coefficients = self.coefficients / len(self.trainer.estimators)\n",
    "        \n",
    "        fold_scores = self.trainer.fold_scores\n",
    "        print(f\"   Fold scores: {fold_scores}\")\n",
    "        print(f\"   Mean CV score: {np.mean(fold_scores):.6f}\")\n",
    "        print(f\"   Std CV score: {np.std(fold_scores):.6f}\")\n",
    "        \n",
    "        return fold_scores, self.coefficients\n",
    "    \n",
    "    def predict(self, test_predictions: Dict[str, np.ndarray]) -> np.ndarray:\n",
    "        \"\"\"Make ensemble predictions.\"\"\"\n",
    "        X_test = pd.DataFrame(test_predictions)\n",
    "        return self.trainer.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329ad8ec",
   "metadata": {},
   "source": [
    "## å¯è§†åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abd40122",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Visualizer:\n",
    "    \"\"\"Handles all visualization tasks.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_ensemble_weights(coefficients: np.ndarray, model_names: List[str], title: str = \"Ridge Ensemble Coefficients\"):\n",
    "        \"\"\"Plot ensemble model coefficients.\"\"\"\n",
    "        sorted_indices = np.argsort(coefficients[0])[::-1]\n",
    "        sorted_coeffs = coefficients[0][sorted_indices]\n",
    "        sorted_names = np.array(model_names)[sorted_indices]\n",
    "        \n",
    "        plt.figure(figsize=(10, len(model_names) * 0.5))\n",
    "        ax = sns.barplot(x=sorted_coeffs, y=sorted_names, palette=\"RdYlGn_r\")\n",
    "        \n",
    "        for i, (value, name) in enumerate(zip(sorted_coeffs, sorted_names)):\n",
    "            ha = \"left\" if value >= 0 else \"right\"\n",
    "            ax.text(value, i, f\"{value:.3f}\", va=\"center\", ha=ha, color=\"black\")\n",
    "        \n",
    "        xlim = ax.get_xlim()\n",
    "        ax.set_xlim(xlim[0] - 0.1 * abs(xlim[0]), xlim[1] + 0.1 * abs(xlim[1]))\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"\")\n",
    "        plt.ylabel(\"\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_model_performance(scores: Dict[str, List[float]]):\n",
    "        \"\"\"Plot model performance comparison.\"\"\"\n",
    "        scores_df = pd.DataFrame(scores)\n",
    "        mean_scores = scores_df.mean().sort_values(ascending=False)\n",
    "        \n",
    "        # Calculate plot limits\n",
    "        min_score, max_score = mean_scores.min(), mean_scores.max()\n",
    "        padding = (max_score - min_score) * 0.5\n",
    "        lower_limit = min_score - padding\n",
    "        upper_limit = max_score + padding\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, len(scores) * 0.5))\n",
    "        \n",
    "        # Box plot\n",
    "        sns.boxplot(data=scores_df, order=mean_scores.index, ax=ax1, orient=\"h\", color=\"grey\")\n",
    "        ax1.set_title(\"Fold Score Distribution\")\n",
    "        ax1.set_xlabel(\"\")\n",
    "        ax1.set_ylabel(\"\")\n",
    "        \n",
    "        # Bar plot\n",
    "        barplot = sns.barplot(x=mean_scores.values, y=mean_scores.index, ax=ax2, color=\"grey\")\n",
    "        ax2.set_title(\"Average Score\")\n",
    "        ax2.set_xlabel(\"\")\n",
    "        ax2.set_xlim(left=lower_limit, right=upper_limit)\n",
    "        ax2.set_ylabel(\"\")\n",
    "        \n",
    "        # Highlight ensemble model\n",
    "        for i, (score, model) in enumerate(zip(mean_scores.values, mean_scores.index)):\n",
    "            color = \"cyan\" if \"ensemble\" in model.lower() else \"grey\"\n",
    "            barplot.patches[i].set_facecolor(color)\n",
    "            ax1.patches[i].set_facecolor(color)\n",
    "            barplot.text(score, i, f\"{score:.6f}\", va=\"center\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_target_distribution(y_train: pd.Series):\n",
    "        \"\"\"Visualize target distribution.\"\"\"\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.hist(y_train, bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        plt.title('Target Distribution')\n",
    "        plt.xlabel('Label Value')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.boxplot(y_train, vert=True)\n",
    "        plt.title('Target Box Plot')\n",
    "        plt.ylabel('Label Value')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_model_correlations(oof_preds: pd.DataFrame):\n",
    "        \"\"\"Display correlation matrix of base model predictions.\"\"\"\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        correlation_matrix = oof_preds.corr()\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "                    square=True, linewidths=0.5)\n",
    "        plt.title('Correlation Matrix of Base Model Predictions')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        return correlation_matrix\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_prediction_distributions(oof_preds: pd.DataFrame):\n",
    "        \"\"\"Analyze prediction distributions.\"\"\"\n",
    "        n_models = len(oof_preds.columns)\n",
    "        n_cols = 2\n",
    "        n_rows = (n_models + 1) // n_cols\n",
    "        \n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, n_rows * 5))\n",
    "        axes = axes.ravel() if n_models > 1 else [axes]\n",
    "        \n",
    "        for i, (model_name, predictions) in enumerate(oof_preds.items()):\n",
    "            if i < len(axes):\n",
    "                axes[i].hist(predictions, bins=30, alpha=0.7, color=f'C{i}', edgecolor='black')\n",
    "                axes[i].set_title(f'{model_name} Predictions Distribution')\n",
    "                axes[i].set_xlabel('Prediction Value')\n",
    "                axes[i].set_ylabel('Frequency')\n",
    "                axes[i].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Hide unused subplots\n",
    "        for i in range(n_models, len(axes)):\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8151580c",
   "metadata": {},
   "source": [
    "## é¢„æµ‹ä»»åŠ¡ç®¡çº¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02ef02e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CryptoPredictor:\n",
    "    \"\"\"Main prediction pipeline class.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.data_processor = DataProcessor(config)\n",
    "        self.visualizer = Visualizer()\n",
    "        \n",
    "        # Initialize models\n",
    "        self.models = [\n",
    "            LightGBMModel(config, boosting_type=\"gbdt\"),\n",
    "            LightGBMModel(config, boosting_type=\"goss\"),\n",
    "            XGBoostModel(config)\n",
    "        ]\n",
    "        \n",
    "        self.ensemble = EnsembleModel(config)\n",
    "        self.results = {}\n",
    "        \n",
    "    def run_pipeline(self) -> str:\n",
    "        \"\"\"\n",
    "        Run the complete prediction pipeline.\n",
    "        \n",
    "        Returns:\n",
    "            Filename of the saved submission\n",
    "        \"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"CRYPTO MARKET PREDICTION PIPELINE\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Load and process data\n",
    "        X_train, y_train, X_test = self.data_processor.load_and_process_data()\n",
    "        \n",
    "        # Data exploration\n",
    "        self._explore_data(X_train, y_train, X_test)\n",
    "        \n",
    "        # Train base models\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"TRAINING BASE MODELS\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        oof_predictions = {}\n",
    "        test_predictions = {}\n",
    "        all_scores = {}\n",
    "        \n",
    "        for model in self.models:\n",
    "            fold_scores, oof_preds = model.train(X_train, y_train)\n",
    "            test_preds = model.predict(X_test)\n",
    "            \n",
    "            model_name = model.get_model_name()\n",
    "            all_scores[model_name] = fold_scores\n",
    "            oof_predictions[model_name] = oof_preds\n",
    "            test_predictions[model_name] = test_preds\n",
    "            \n",
    "            # Cleanup\n",
    "            del model.trainer\n",
    "            gc.collect()\n",
    "        \n",
    "        # Save base model predictions\n",
    "        oof_df = pd.DataFrame(oof_predictions)\n",
    "        test_df = pd.DataFrame(test_predictions)\n",
    "        joblib.dump(oof_df, os.path.join(self.config.models_dir, \"oof_preds.pkl\"))\n",
    "        joblib.dump(test_df, os.path.join(self.config.models_dir, \"test_preds.pkl\"))\n",
    "        \n",
    "        # Train ensemble model\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"TRAINING ENSEMBLE MODEL\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        ensemble_scores, coefficients = self.ensemble.train(oof_predictions, y_train)\n",
    "        ensemble_test_preds = self.ensemble.predict(test_predictions)\n",
    "        \n",
    "        all_scores[\"Ridge (ensemble)\"] = ensemble_scores\n",
    "        \n",
    "        # Print results summary\n",
    "        self._print_results_summary(all_scores)\n",
    "        \n",
    "        # Visualizations\n",
    "        print(\"\\nGenerating visualizations...\")\n",
    "        self.visualizar_resultados(y_train, oof_df, all_scores, coefficients, list(oof_predictions.keys()))\n",
    "        \n",
    "        # Analysis\n",
    "        self._analyze_results(y_train, oof_df, X_train)\n",
    "        \n",
    "        # Save submission\n",
    "        submission_filename = self._save_submission(ensemble_test_preds, ensemble_scores)\n",
    "        \n",
    "        # Export comprehensive results\n",
    "        self._export_results(all_scores, X_train, y_train, X_test)\n",
    "        \n",
    "        print(f\"\\n\" + \"=\" * 60)\n",
    "        print(f\"Submission saved as: {submission_filename}\")\n",
    "        print(f\"Final ensemble CV score: {np.mean(ensemble_scores):.6f}\")\n",
    "        print(\"=\" * 60)\n",
    "        print(\"Process completed successfully!\")\n",
    "        \n",
    "        return submission_filename\n",
    "    \n",
    "    def _explore_data(self, X_train: pd.DataFrame, y_train: pd.Series, X_test: pd.DataFrame):\n",
    "        \"\"\"Explore and visualize the dataset.\"\"\"\n",
    "        print(\"\\n=== DATASET OVERVIEW ===\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"Training samples: {X_train.shape[0]:,}\")\n",
    "        print(f\"Test samples: {X_test.shape[0]:,}\")\n",
    "        print(f\"Features: {X_train.shape[1]:,}\")\n",
    "        print(f\"Target statistics:\")\n",
    "        print(f\"  Mean: {y_train.mean():.6f}\")\n",
    "        print(f\"  Std:  {y_train.std():.6f}\")\n",
    "        print(f\"  Min:  {y_train.min():.6f}\")\n",
    "        print(f\"  Max:  {y_train.max():.6f}\")\n",
    "        \n",
    "        # Visualize target distribution\n",
    "        self.visualizer.plot_target_distribution(y_train)\n",
    "    \n",
    "    def visualizar_resultados(self, y_train: pd.Series, oof_df: pd.DataFrame, \n",
    "                             all_scores: Dict[str, List[float]], coefficients: np.ndarray, \n",
    "                             model_names: List[str]):\n",
    "        \"\"\"Generate all visualizations.\"\"\"\n",
    "        # Ensemble weights\n",
    "        self.visualizer.plot_ensemble_weights(\n",
    "            coefficients, \n",
    "            model_names,\n",
    "            \"Ridge Ensemble Coefficients\"\n",
    "        )\n",
    "        \n",
    "        # Model performance comparison\n",
    "        self.visualizer.plot_model_performance(all_scores)\n",
    "        \n",
    "        # Model correlations\n",
    "        correlation_matrix = self.visualizer.plot_model_correlations(oof_df)\n",
    "        print(\"\\nBase Model Correlations:\")\n",
    "        print(correlation_matrix)\n",
    "        \n",
    "        # Prediction distributions\n",
    "        self.visualizer.plot_prediction_distributions(oof_df)\n",
    "    \n",
    "    def _analyze_results(self, y_train: pd.Series, oof_df: pd.DataFrame, X_train: pd.DataFrame):\n",
    "        \"\"\"Analyze and print detailed results.\"\"\"\n",
    "        print(\"\\n=== INDIVIDUAL MODEL PERFORMANCE ===\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for model_name, predictions in oof_df.items():\n",
    "            corr = pearsonr(y_train, predictions)[0]\n",
    "            print(f\"{model_name:20s}: {corr:.6f}\")\n",
    "        \n",
    "        print(\"\\n=== FEATURE ENGINEERING SUMMARY ===\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"Original features: {len([col for col in X_train.columns if col.startswith('X')])}\")\n",
    "        print(f\"Interaction features: {len([col for col in X_train.columns if 'interaction' in col])}\")\n",
    "        print(f\"Market features: {len([col for col in X_train.columns if any(x in col for x in ['ratio', 'imbalance', 'pressure', 'liquidity'])])}\")\n",
    "        print(f\"Total features: {X_train.shape[1]}\")\n",
    "        \n",
    "        print(\"\\n=== MEMORY OPTIMIZATION ===\")\n",
    "        print(\"-\" * 50)\n",
    "        memory_usage = X_train.memory_usage(deep=True).sum() / 1024**2\n",
    "        print(f\"Training data memory usage: {memory_usage:.2f} MB\")\n",
    "        \n",
    "        print(\"\\n=== GPU UTILIZATION ===\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"GPU enabled: {self.config.use_gpu}\")\n",
    "        if self.config.use_gpu:\n",
    "            print(f\"GPU device ID: {self.config.gpu_id}\")\n",
    "            print(\"Models using GPU: LightGBM, XGBoost\")\n",
    "        else:\n",
    "            print(\"Running on CPU\")\n",
    "    \n",
    "    def _print_results_summary(self, scores: Dict[str, List[float]]):\n",
    "        \"\"\"Print detailed results summary.\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"FINAL MODEL PERFORMANCE SUMMARY\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        scores_df = pd.DataFrame(scores)\n",
    "        mean_scores = scores_df.mean().sort_values(ascending=False)\n",
    "        \n",
    "        print(\"\\nModel Rankings (by mean CV score):\")\n",
    "        print(\"-\" * 40)\n",
    "        for i, (model, score) in enumerate(mean_scores.items(), 1):\n",
    "            std_score = scores_df[model].std()\n",
    "            print(f\"{i}. {model:20s} - Mean: {score:.6f} (Â±{std_score:.6f})\")\n",
    "        \n",
    "        print(\"\\nDetailed Fold Scores:\")\n",
    "        print(\"-\" * 40)\n",
    "        for model in mean_scores.index:\n",
    "            fold_scores = scores[model]\n",
    "            print(f\"\\n{model}:\")\n",
    "            for fold, score in enumerate(fold_scores, 1):\n",
    "                print(f\"   Fold {fold}: {score:.6f}\")\n",
    "    \n",
    "    def _save_submission(self, predictions: np.ndarray, scores: List[float]) -> str:\n",
    "        \"\"\"Save predictions to submission file.\"\"\"\n",
    "        sub = pd.read_csv(self.config.sample_sub_path)\n",
    "        sub[\"prediction\"] = predictions\n",
    "        \n",
    "        mean_score = np.mean(scores)\n",
    "        filename = f\"sub_ridge_{mean_score:.6f}.csv\"\n",
    "        filepath = os.path.join(self.config.results_dir, filename)\n",
    "        sub.to_csv(filepath, index=False)\n",
    "        \n",
    "        return filename\n",
    "    \n",
    "    def _export_results(self, all_scores: Dict[str, List[float]], \n",
    "                       X_train: pd.DataFrame, y_train: pd.Series, X_test: pd.DataFrame):\n",
    "        \"\"\"Export comprehensive results summary.\"\"\"\n",
    "        # Load saved predictions for analysis\n",
    "        oof_preds = joblib.load(os.path.join(self.config.models_dir, \"oof_preds.pkl\"))\n",
    "        \n",
    "        # Create comprehensive results summary\n",
    "        results_summary = {\n",
    "            'configuration': {\n",
    "                'n_folds': self.config.n_folds,\n",
    "                'seed': self.config.seed,\n",
    "                'use_gpu': self.config.use_gpu,\n",
    "                'n_optuna_trials': self.config.n_optuna_trials\n",
    "            },\n",
    "            'data_info': {\n",
    "                'train_samples': X_train.shape[0],\n",
    "                'test_samples': X_test.shape[0],\n",
    "                'total_features': X_train.shape[1],\n",
    "                'target_mean': float(y_train.mean()),\n",
    "                'target_std': float(y_train.std())\n",
    "            },\n",
    "            'model_performance': {},\n",
    "            'ensemble_coefficients': self.ensemble.coefficients.tolist() if self.ensemble.coefficients is not None else None\n",
    "        }\n",
    "        \n",
    "        # Add individual model performances\n",
    "        for model_name, predictions in oof_preds.items():\n",
    "            corr = pearsonr(y_train, predictions)[0]\n",
    "            results_summary['model_performance'][model_name] = float(corr)\n",
    "        \n",
    "        # Save results summary\n",
    "        results_file = os.path.join(self.config.results_dir, 'results_summary.json')\n",
    "        with open(results_file, 'w') as f:\n",
    "            json.dump(results_summary, f, indent=2)\n",
    "        \n",
    "        print(f\"ðŸ“Š Results summary saved to: {results_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b07f1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration initialized!\n",
      "Training data path: ../kaggle/input/drw-crypto-market-prediction/train.parquet\n",
      "Test data path: ../kaggle/input/drw-crypto-market-prediction/test.parquet\n",
      "GPU enabled: True\n",
      "============================================================\n",
      "CRYPTO MARKET PREDICTION PIPELINE\n",
      "============================================================\n",
      "Loading data...\n",
      "Reducing memory usage for: train\n",
      "--- Memory usage before: 3374.26 MB\n",
      "--- Memory usage after: 843.57 MB\n",
      "--- Decreased memory usage by 75.0%\n",
      "\n",
      "Reducing memory usage for: test\n",
      "--- Memory usage before: 3448.84 MB\n",
      "--- Memory usage after: 862.21 MB\n",
      "--- Decreased memory usage by 75.0%\n",
      "\n",
      "Creating features...\n",
      "Training data shape: (525887, 871)\n",
      "Test data shape: (538150, 871)\n",
      "Number of features: 871\n",
      "\n",
      "=== DATASET OVERVIEW ===\n",
      "--------------------------------------------------\n",
      "Training samples: 525,887\n",
      "Test samples: 538,150\n",
      "Features: 871\n",
      "Target statistics:\n",
      "  Mean: 0.000000\n",
      "  Std:  0.000000\n",
      "  Min:  -24.421875\n",
      "  Max:  20.734375\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING BASE MODELS\n",
      "============================================================\n",
      "Training LightGBM (gbdt)...\n",
      "Training LGBMRegressor\n",
      "\n",
      "--- Fold 0 - _pearsonr: 0.135342 - Time: 70.12 s\n",
      "--- Fold 1 - _pearsonr: 0.097771 - Time: 72.33 s\n",
      "--- Fold 2 - _pearsonr: 0.067621 - Time: 77.83 s\n",
      "--- Fold 3 - _pearsonr: 0.152706 - Time: 70.81 s\n",
      "--- Fold 4 - _pearsonr: 0.062459 - Time: 70.59 s\n",
      "\n",
      "------ Overall _pearsonr: 0.092851 - Mean _pearsonr: 0.103180 Â± 0.035886 - Time: 363.32 s\n",
      "   Fold scores: [0.13534225265777083, 0.09777090485394635, 0.06762132210006491, 0.15270559934937084, 0.06245881271011697]\n",
      "   Mean CV score: 0.103180\n",
      "   Std CV score: 0.035886\n",
      "Training LightGBM (goss)...\n",
      "Training LGBMRegressor\n",
      "\n",
      "--- Fold 0 - _pearsonr: 0.174419 - Time: 134.71 s\n",
      "--- Fold 1 - _pearsonr: 0.104235 - Time: 139.02 s\n",
      "--- Fold 2 - _pearsonr: 0.028612 - Time: 150.97 s\n",
      "--- Fold 3 - _pearsonr: 0.117456 - Time: 148.09 s\n",
      "--- Fold 4 - _pearsonr: 0.078308 - Time: 158.37 s\n",
      "\n",
      "------ Overall _pearsonr: 0.092698 - Mean _pearsonr: 0.100606 Â± 0.047803 - Time: 733.13 s\n",
      "   Fold scores: [0.17441886704192355, 0.10423454674920377, 0.028612184943893573, 0.11745634992361181, 0.07830778292646048]\n",
      "   Mean CV score: 0.100606\n",
      "   Std CV score: 0.047803\n",
      "Training XGBoost...\n",
      "Training XGBRegressor\n",
      "\n",
      "--- Fold 0 - _pearsonr: 0.201074 - Time: 131.10 s\n",
      "--- Fold 1 - _pearsonr: 0.121948 - Time: 132.00 s\n",
      "--- Fold 2 - _pearsonr: 0.073183 - Time: 133.26 s\n",
      "--- Fold 3 - _pearsonr: 0.126316 - Time: 135.04 s\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    # Initialize configuration\n",
    "    config = Config()\n",
    "    print(f\"Configuration initialized!\")\n",
    "    print(f\"Training data path: {config.train_path}\")\n",
    "    print(f\"Test data path: {config.test_path}\")\n",
    "    print(f\"GPU enabled: {config.use_gpu}\")\n",
    "    \n",
    "    # Create and run predictor\n",
    "    predictor = CryptoPredictor(config)\n",
    "    submission_file = predictor.run_pipeline()\n",
    "    \n",
    "    print(f\"\\nðŸŽ‰ Prediction pipeline completed!\")\n",
    "    print(f\"ðŸ“ Submission file: {submission_file}\")\n",
    "    print(f\"ðŸŽ¯ Pipeline execution completed successfully!\")\n",
    "    print(f\"ðŸ“ˆ Best model: Ridge Ensemble\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
